{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfe67489",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../utility_box/')\n",
    "import image_utils as iu\n",
    "import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e03d8050",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cpath import WSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eab69bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openslide import OpenSlide\n",
    "from pathlib import Path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33eeb21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "912f5013",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_positive_cases(positive_cases, val_ratio):\n",
    "    train_positive_cases = pd.DataFrame()\n",
    "    val_positive_cases = pd.DataFrame()\n",
    "\n",
    "    # Group by 'group'\n",
    "    grouped = positive_cases.groupby('group')\n",
    "\n",
    "    for name, group in grouped:\n",
    "        if len(group) > 1:  # Ensure at least 2 samples to split\n",
    "            # Calculate the number of samples for validation\n",
    "            n_val = int(len(group) * val_ratio)\n",
    "            train, val = train_test_split(group, test_size=n_val, random_state=42)\n",
    "            train_positive_cases = pd.concat([train_positive_cases, train])\n",
    "            val_positive_cases = pd.concat([val_positive_cases, val])\n",
    "        else:\n",
    "            # If only one instance, add to train set only\n",
    "            train_positive_cases = pd.concat([train_positive_cases, group])\n",
    "\n",
    "    return train_positive_cases.reset_index(drop=True), val_positive_cases.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "278d0761",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_numpy_mask(poly, contours, width, height, shift_x=0, shift_y=0, scale=1):\n",
    "    \n",
    "    min_x, min_y, max_x, max_y = poly.bounds\n",
    "    poly_mask=np.zeros((width, height), dtype=np.uint8)\n",
    "\n",
    "    for contour in contours:\n",
    "        shifted_coords = np.array([(x - min_x, y - min_y) for x, y in np.array(contour)], dtype=np.int32)\n",
    "        shifted_coords[:,0]=(shifted_coords[:,0]+shift_x)*scale\n",
    "        shifted_coords[:,1]=(shifted_coords[:,1]+shift_y)*scale\n",
    "        cv2contour=shifted_coords.reshape((-1, 1, 2))\n",
    "        cv2.fillPoly(poly_mask, [cv2contour], color=1)\n",
    "    \n",
    "    return poly_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e0e369d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bondary_coords(poly, patch_size):\n",
    "    min_x, min_y, max_x, max_y = poly.bounds\n",
    "    width=int(max_x - min_x)\n",
    "    height=int(max_y - min_y)\n",
    "\n",
    "    if patch_size>=max(width, height):\n",
    "        diff=patch_size-max(width, height)\n",
    "        delta=diff+patch_size+random.randint(0,patch_size)\n",
    "        \n",
    "    else:\n",
    "        diff=max(width, height)-patch_size\n",
    "        delta=diff+patch_size+random.randint(0,patch_size)\n",
    "    \n",
    "    start_x=min_x-delta\n",
    "    start_y=min_y-delta\n",
    "    \n",
    "    stop_x=max_x+delta\n",
    "    stop_y=max_y+delta\n",
    "\n",
    "    return start_x,start_y,stop_x,stop_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9cd9a2",
   "metadata": {},
   "source": [
    "# Create Sampling Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1671eb1a",
   "metadata": {},
   "source": [
    "## CAMELYON17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bdd0012f",
   "metadata": {},
   "outputs": [],
   "source": [
    "annFolder=Path('/workspace/data/PublicDatasets/CAMELYON17/tumor_geoms')\n",
    "wsisFolder=Path('/workspace/data/PublicDatasets/CAMELYON17/images')\n",
    "annsPath=list(annFolder.iterdir())\n",
    "annsName=[annPath.stem for annPath in annsPath]\n",
    "stages=pd.read_csv('/workspace/data/PublicDatasets/CAMELYON17/stages.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "511f092a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_distribution=[]\n",
    "for idx, row in stages.iterrows():\n",
    "    \n",
    "    if 'zip' in row['patient']:\n",
    "        continue\n",
    "\n",
    "    wsi_path=Path(f\"/workspace/data/PublicDatasets/CAMELYON17/images/{row['patient']}\")\n",
    "\n",
    "    if wsi_path.exists():\n",
    "    \n",
    "        slideStem=row['patient'].split('.')[0]\n",
    "        \n",
    "        if row['stage']=='negative':\n",
    "            tempDict={}\n",
    "            \n",
    "            tempDict['wsi_name']=row['patient']\n",
    "            tempDict['group']=row['stage']\n",
    "            tempDict['ann_name']=None\n",
    "            tempDict['ann_folder']=None\n",
    "            tempDict['wsi_folder']='/workspace/data/PublicDatasets/CAMELYON17/images'\n",
    "            tempDict['mpp']=0.25\n",
    "            data_distribution.append(tempDict)\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            if slideStem in annsName:\n",
    "                tempDict={}\n",
    "                tempDict['wsi_name']=row['patient']\n",
    "                tempDict['group']=row['stage']\n",
    "                tempDict['ann_name']=f\"{slideStem}.pkl\"\n",
    "                tempDict['ann_folder']='/workspace/data/PublicDatasets/CAMELYON17/tumor_geoms'\n",
    "                tempDict['wsi_folder']='/workspace/data/PublicDatasets/CAMELYON17/images'\n",
    "                tempDict['mpp']=0.25\n",
    "                data_distribution.append(tempDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f121e8c",
   "metadata": {},
   "source": [
    "## CAMELYON16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "427ab0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "annFolder=Path('/workspace/data/PublicDatasets/CAMELYON16/tumor_geoms')\n",
    "wsisFolder=Path('/workspace/data/PublicDatasets/CAMELYON16/images')\n",
    "annsPath=list(annFolder.iterdir())\n",
    "annsName=[annPath.stem for annPath in annsPath]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "654934b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for wsiFullName in list(wsisFolder.iterdir()):\n",
    "    slideStem=wsiFullName.stem\n",
    "    wsi_path=Path(f\"/workspace/data/PublicDatasets/CAMELYON16/images/{wsiFullName.name}\")\n",
    "    if wsi_path.exists():\n",
    "        if slideStem in annsName:\n",
    "            \n",
    "            tempDict={}\n",
    "            tempDict['wsi_name']=wsiFullName.name\n",
    "            tempDict['group']='tumor'\n",
    "            tempDict['ann_name']=f\"{slideStem}.pkl\"\n",
    "            tempDict['ann_folder']='/workspace/data/PublicDatasets/CAMELYON16/tumor_geoms'\n",
    "            tempDict['wsi_folder']='/workspace/data/PublicDatasets/CAMELYON16/images'\n",
    "            tempDict['mpp']=0.25\n",
    "            \n",
    "            data_distribution.append(tempDict)\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            tempDict={}\n",
    "            tempDict['wsi_name']=wsiFullName.name\n",
    "            tempDict['group']='negative'\n",
    "            tempDict['ann_name']=None\n",
    "            tempDict['ann_folder']=None\n",
    "            tempDict['wsi_folder']='/workspace/data/PublicDatasets/CAMELYON16/images'\n",
    "            tempDict['mpp']=0.25\n",
    "        \n",
    "            data_distribution.append(tempDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e71a869",
   "metadata": {},
   "source": [
    "## compileDistribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "09c7c3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_distribution=pd.DataFrame(data_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa6c9792",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_distribution.to_csv('data_distribution.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ce64561e-a2bd-4bad-b868-4274cf7058d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(766, 6)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_distribution.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203eaef5",
   "metadata": {},
   "source": [
    "# split into test, train, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "155a79b7-f525-4316-a85e-dc5ba0fa0a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fc4bec96",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_distribution=pd.read_csv('data_distribution.csv')\n",
    "\n",
    "positive_cases=data_distribution[data_distribution['ann_name'].notna()]\n",
    "negative_cases=data_distribution[data_distribution['ann_name'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "99b0f8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio=0.80\n",
    "val_ratio=0.10\n",
    "test_ratio=0.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "89f1d5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_positive_cases, temp_positive_cases = split_positive_cases(positive_cases, val_ratio+test_ratio)\n",
    "train_negative_cases, temp_negative_cases = train_test_split(negative_cases, test_size=val_ratio+test_ratio, random_state=42)\n",
    "\n",
    "val_positive_cases, test_positive_cases = split_positive_cases(temp_positive_cases, test_ratio/(test_ratio+val_ratio))\n",
    "val_negative_cases, test_negative_cases = train_test_split(temp_negative_cases, test_size=test_ratio/(test_ratio+val_ratio), random_state=42)\n",
    "\n",
    "train_distribution = pd.concat([train_positive_cases, train_negative_cases]).reset_index(drop=True)\n",
    "val_distribution = pd.concat([val_positive_cases, val_negative_cases]).reset_index(drop=True)\n",
    "test_distribution = pd.concat([test_positive_cases, test_negative_cases]).reset_index(drop=True)\n",
    "\n",
    "assert val_distribution.shape[0]+test_distribution.shape[0]+train_distribution.shape[0] ==data_distribution.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ea98eaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_distribution.to_csv('train_distribution.csv', index=False)\n",
    "val_distribution.to_csv('val_distribution.csv', index=False)\n",
    "test_distribution.to_csv('test_distribution.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fbb3e651-d8f4-49be-896f-98176781d45e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "group\n",
       "negative    56\n",
       "tumor       16\n",
       "itc          1\n",
       "macro        1\n",
       "micro        1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_distribution['group'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "85520f3f-1a60-4ead-b36d-d4c1b07e0cfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "group\n",
       "negative    445\n",
       "tumor       128\n",
       "micro        14\n",
       "itc          13\n",
       "macro        13\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_distribution['group'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "471477f5-59aa-4f06-b6ee-c8381c79f729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "group\n",
       "negative    56\n",
       "tumor       16\n",
       "itc          2\n",
       "macro        2\n",
       "micro        2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_distribution['group'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
